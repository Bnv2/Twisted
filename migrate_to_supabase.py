import streamlit as st
from streamlit_gsheets import GSheetsConnection
from modules.supabase_db import get_supabase
import pandas as pd
import numpy as np

def clean_dates(df, date_columns):
    """Convert DD/MM/YYYY to YYYY-MM-DD for Supabase"""
    for col in date_columns:
        if col in df.columns:
            # Dayfirst=True handles the DD/MM/YYYY format
            df[col] = pd.to_datetime(df[col], dayfirst=True, errors='coerce')
            # Convert to string format YYYY-MM-DD or None if invalid
            df[col] = df[col].dt.strftime('%Y-%m-%d').replace({np.nan: None})
    return df

def migrate_all_data():
    st.title("üöÄ Finalizing Migration")
    
    gsheets = st.connection("gsheets", type=GSheetsConnection)
    supabase = get_supabase()

    sheets = [
        "Staff", "Events", "Event_Financials", "Event_Contacts",
        "Logistics_Details", "Event_Reports", "Inventory", 
        "Event_Sales", "Event_Staffing", "Staff_Database"
    ]

    for sheet_name in sheets:
        try:
            df = gsheets.read(worksheet=sheet_name, ttl=0)
            if df.empty: continue

            # --- FIX 1: Cleaning NaN/Infinity ---
            df = df.replace([np.nan, np.inf, -np.inf], None)
            df = df.where(pd.notnull(df), None)

            # --- FIX 2: Formatting Dates ---
            # List every column that contains a date in your Google Sheets
            date_cols = ['Date', 'End_Date', 'Rent_Paid_Date', 'Rent_Due_Date', 
                         'Payment_Date', 'Due_Date', 'Report_Date']
            df = clean_dates(df, date_cols)

            # --- FIX 3: Column Mappings ---
            if sheet_name == "Event_Sales":
                df = df.rename(columns={
                    "Eftpos": "Card_Sales",     # Fixes the 'Eftpos' error
                    "Cash": "Cash_Sales",
                    "Total": "Total_Revenue",
                    "Opening Float": "Opening_Float",
                    "Closing Float": "Closing_Float"
                })

            if supabase.update_table(sheet_name, df):
                st.success(f"‚úÖ {sheet_name} Migrated!")
            else:
                st.error(f"‚ùå {sheet_name} Failed.")

        except Exception as e:
            st.error(f"Error on {sheet_name}: {e}")

if __name__ == "__main__":
    migrate_all_data()
# import streamlit as st
# from streamlit_gsheets import GSheetsConnection
# from modules.supabase_db import get_supabase
# import pandas as pd
# import numpy as np
# from pathlib import Path
# from datetime import datetime

# def migrate_all_data():
#     """One-time migration from Google Sheets to Supabase with Data Cleaning"""
    
#     st.title("üöÄ Supabase Migration Tool")
#     st.info("Watch the logs in the bottom right for detailed progress.")
    
#     print("üöÄ Starting migration to Supabase...")
    
#     # Connect to both
#     try:
#         gsheets = st.connection("gsheets", type=GSheetsConnection)
#         supabase = get_supabase()
#     except Exception as e:
#         st.error(f"Connection Error: {e}")
#         return

#     # Your 10 tables
#     sheets = [
#         "Staff", "Events", "Event_Financials", "Event_Contacts",
#         "Logistics_Details", "Event_Reports", "Inventory", 
#         "Event_Sales", "Event_Staffing", "Staff_Database"
#     ]
    
#     successful = 0
#     failed = 0
    
#     for sheet_name in sheets:
#         try:
#             print(f"üì• Processing {sheet_name}...")
            
#             # 1. Read from Google Sheets
#             df = gsheets.read(worksheet=sheet_name, ttl=0)
            
#             if df.empty:
#                 print(f"  ‚ö†Ô∏è  {sheet_name} is empty, skipping...")
#                 continue

#             # --- üõ†Ô∏è FIX 1: CLEAN THE 'NAN' DATA ---
#             # Replace 'NaN', 'inf', and empty strings with None so Supabase doesn't crash
#             df = df.replace([np.nan, np.inf, -np.inf], None)
#             # Ensure everything is a standard Python type
#             df = df.where(pd.notnull(df), None)

#             # --- üõ†Ô∏è FIX 2: HANDLE COLUMN MISMATCHES ---
#             # If Google Sheets uses 'Cash' or 'Card', rename them to match your reverse_map
#             if sheet_name == "Event_Sales":
#                 rename_map = {
#                     "Cash": "Cash_Sales",
#                     "Card": "Card_Sales",
#                     "Total": "Total_Revenue"
#                 }
#                 df = df.rename(columns=rename_map)
            
#             # 2. Write to Supabase
#             # This calls the update_table function in your modules/supabase_db.py
#             if supabase.update_table(sheet_name, df):
#                 st.success(f"‚úÖ {sheet_name}: Migrated {len(df)} rows")
#                 print(f"  ‚úÖ Migrated {len(df)} rows to Supabase")
#                 successful += 1
#             else:
#                 st.error(f"‚ùå {sheet_name}: Failed to update table")
#                 failed += 1
            
#         except Exception as e:
#             st.error(f"‚ùå Error with {sheet_name}: {e}")
#             print(f"  ‚ùå Error with {sheet_name}: {e}")
#             failed += 1
    
#     st.divider()
#     st.balloons()
#     st.write(f"üéâ Migration Complete! {successful}/{len(sheets)} successful.")

# if __name__ == "__main__":
#     migrate_all_data()
# # import streamlit as st
# # from streamlit_gsheets import GSheetsConnection
# # from modules.supabase_db import get_supabase
# # import pandas as pd
# # from pathlib import Path
# # from datetime import datetime

# # def migrate_all_data():
# #     """One-time migration from Google Sheets to Supabase"""
    
# #     print("üöÄ Starting migration to Supabase...")
# #     print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
# #     # Connect to both
# #     gsheets = st.connection("gsheets", type=GSheetsConnection)
# #     supabase = get_supabase()
    
# #     # Your 10 tables
# #     sheets = [
# #         "Staff",
# #         "Events",
# #         "Event_Financials",
# #         "Event_Contacts",
# #         "Logistics_Details",
# #         "Event_Reports",
# #         "Inventory",
# #         "Event_Sales",
# #         "Event_Staffing",
# #         "Staff_Database"
# #     ]
    
# #     # Create backup directory
# #     backup_dir = Path("data/backups")
# #     backup_dir.mkdir(parents=True, exist_ok=True)
    
# #     successful = 0
# #     failed = 0
    
# #     for sheet_name in sheets:
# #         try:
# #             print(f"üì• Processing {sheet_name}...")
            
# #             # Read from Google Sheets
# #             df = gsheets.read(worksheet=sheet_name, ttl=0)
            
# #             if df.empty:
# #                 print(f"  ‚ö†Ô∏è  {sheet_name} is empty, skipping...\n")
# #                 continue
            
# #             # Backup to CSV
# #             timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
# #             csv_path = backup_dir / f"{sheet_name}_{timestamp}.csv"
# #             df.to_csv(csv_path, index=False)
# #             print(f"  üíæ Backed up to {csv_path}")
            
# #             # Write to Supabase
# #             if supabase.update_table(sheet_name, df):
# #                 print(f"  ‚úÖ Migrated {len(df)} rows to Supabase")
# #                 successful += 1
# #             else:
# #                 print(f"  ‚ùå Failed to migrate {sheet_name}")
# #                 failed += 1
            
# #             print()  # Blank line
            
# #         except Exception as e:
# #             print(f"  ‚ùå Error with {sheet_name}: {e}\n")
# #             failed += 1
    
# #     print("=" * 50)
# #     print(f"üéâ Migration Complete!")
# #     print(f"‚úÖ Successful: {successful}/{len(sheets)}")
# #     print(f"‚ùå Failed: {failed}/{len(sheets)}")
# #     print(f"üíæ Backups saved to: {backup_dir}")
# #     print("=" * 50)

# # if __name__ == "__main__":
# #     migrate_all_data()
